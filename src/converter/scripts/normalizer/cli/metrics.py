"""
Metrics Command - å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºã‚³ãƒãƒ³ãƒ‰

ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¿ã‚°ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€è‹±èªåˆ¤å®šï¼‰ã‚’è¡¨ç¤ºã€‚
"""
from __future__ import annotations

import json
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    pass

from normalizer.io.session import load_latest_session


def cmd_metrics(output_json: bool = False) -> int:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¡¨ç¤º"""
    session = load_latest_session()
    if session is None:
        print("ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
        return 0

    metrics = {
        "session": session.name,
        "title": {"total": 0, "valid": 0, "rate": 0.0, "issues": []},
        "tags": {"total": 0, "avg_consistency": 0.0, "matched": 0, "unmatched": 0},
        "format": {"total": 0, "valid": 0, "rate": 0.0, "common_issues": {}},
        "english": {"total": 0, "detected": 0, "avg_score": 0.0}
    }

    _load_title_metrics(session, metrics)
    _load_tag_metrics(session, metrics)
    _load_format_metrics(session, metrics)
    _load_english_metrics(session, metrics)

    # å‡ºåŠ›
    if output_json:
        print(json.dumps(metrics, ensure_ascii=False, indent=2))
        return 0

    _print_metrics(metrics)
    return 0


def _load_title_metrics(session, metrics: dict) -> None:
    """ã‚¿ã‚¤ãƒˆãƒ«å“è³ªãƒ­ã‚°èª­ã¿è¾¼ã¿"""
    title_log = session / "title_quality.jsonl"
    if not title_log.exists():
        return

    try:
        issue_counts = {}
        for line in title_log.read_text(encoding="utf-8").strip().split("\n"):
            if not line:
                continue
            entry = json.loads(line)
            metrics["title"]["total"] += 1
            if entry.get("is_valid", False):
                metrics["title"]["valid"] += 1
            for issue in entry.get("issues", []):
                issue_counts[issue] = issue_counts.get(issue, 0) + 1
        if metrics["title"]["total"] > 0:
            metrics["title"]["rate"] = metrics["title"]["valid"] / metrics["title"]["total"]
        metrics["title"]["issues"] = sorted(issue_counts.items(), key=lambda x: -x[1])[:5]
    except (json.JSONDecodeError, OSError):
        pass


def _load_tag_metrics(session, metrics: dict) -> None:
    """ã‚¿ã‚°å“è³ªãƒ­ã‚°èª­ã¿è¾¼ã¿"""
    tag_log = session / "tag_quality.jsonl"
    if not tag_log.exists():
        return

    try:
        total_consistency = 0.0
        for line in tag_log.read_text(encoding="utf-8").strip().split("\n"):
            if not line:
                continue
            entry = json.loads(line)
            metrics["tags"]["total"] += 1
            total_consistency += entry.get("consistency_rate", 0.0)
            metrics["tags"]["matched"] += len(entry.get("matched_tags", []))
            metrics["tags"]["unmatched"] += len(entry.get("unmatched_tags", []))
        if metrics["tags"]["total"] > 0:
            metrics["tags"]["avg_consistency"] = total_consistency / metrics["tags"]["total"]
    except (json.JSONDecodeError, OSError):
        pass


def _load_format_metrics(session, metrics: dict) -> None:
    """ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå“è³ªãƒ­ã‚°èª­ã¿è¾¼ã¿"""
    format_log = session / "format_quality.jsonl"
    if not format_log.exists():
        return

    try:
        issue_counts = {}
        for line in format_log.read_text(encoding="utf-8").strip().split("\n"):
            if not line:
                continue
            entry = json.loads(line)
            metrics["format"]["total"] += 1
            if entry.get("is_valid", False):
                metrics["format"]["valid"] += 1
            for issue in entry.get("issues", []):
                issue_counts[issue] = issue_counts.get(issue, 0) + 1
        if metrics["format"]["total"] > 0:
            metrics["format"]["rate"] = metrics["format"]["valid"] / metrics["format"]["total"]
        metrics["format"]["common_issues"] = dict(sorted(issue_counts.items(), key=lambda x: -x[1])[:5])
    except (json.JSONDecodeError, OSError):
        pass


def _load_english_metrics(session, metrics: dict) -> None:
    """è‹±èªæ–‡æ›¸åˆ¤å®šãƒ­ã‚°èª­ã¿è¾¼ã¿"""
    english_log = session / "english_detection.jsonl"
    if not english_log.exists():
        return

    try:
        total_score = 0.0
        for line in english_log.read_text(encoding="utf-8").strip().split("\n"):
            if not line:
                continue
            entry = json.loads(line)
            metrics["english"]["total"] += 1
            total_score += entry.get("score", 0.0)
            if entry.get("is_complete_english_doc", False):
                metrics["english"]["detected"] += 1
        if metrics["english"]["total"] > 0:
            metrics["english"]["avg_score"] = total_score / metrics["english"]["total"]
    except (json.JSONDecodeError, OSError):
        pass


def _print_metrics(metrics: dict) -> None:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º"""
    print(f"\n{'='*60}")
    print("  ğŸ“Š å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹")
    print(f"{'='*60}")
    print(f"  ã‚»ãƒƒã‚·ãƒ§ãƒ³: {metrics['session']}")

    # ã‚¿ã‚¤ãƒˆãƒ«å“è³ª
    print(f"\nğŸ“ ã‚¿ã‚¤ãƒˆãƒ«å“è³ª:")
    print(f"   å‡¦ç†ä»¶æ•°: {metrics['title']['total']}")
    print(f"   æœ‰åŠ¹ç‡: {metrics['title']['rate']*100:.1f}%")
    if metrics["title"]["issues"]:
        print("   é »å‡ºå•é¡Œ:")
        for issue, count in metrics["title"]["issues"][:3]:
            print(f"     - {issue}: {count}ä»¶")

    # ã‚¿ã‚°å“è³ª
    print(f"\nğŸ·ï¸ ã‚¿ã‚°ä¸€è²«æ€§:")
    print(f"   å‡¦ç†ä»¶æ•°: {metrics['tags']['total']}")
    print(f"   å¹³å‡ä¸€è²«æ€§ç‡: {metrics['tags']['avg_consistency']*100:.1f}%")
    print(f"   è¾æ›¸ãƒãƒƒãƒ: {metrics['tags']['matched']}ä»¶ / æœªãƒãƒƒãƒ: {metrics['tags']['unmatched']}ä»¶")

    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå“è³ª
    print(f"\nğŸ“„ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæº–æ‹ :")
    print(f"   å‡¦ç†ä»¶æ•°: {metrics['format']['total']}")
    print(f"   æº–æ‹ ç‡: {metrics['format']['rate']*100:.1f}%")
    if metrics["format"]["common_issues"]:
        print("   é »å‡ºå•é¡Œ:")
        for issue, count in list(metrics["format"]["common_issues"].items())[:3]:
            print(f"     - {issue}: {count}ä»¶")

    # è‹±èªæ–‡æ›¸åˆ¤å®š
    print(f"\nğŸŒ è‹±èªæ–‡æ›¸åˆ¤å®š:")
    print(f"   å‡¦ç†ä»¶æ•°: {metrics['english']['total']}")
    print(f"   è‹±èªæ–‡æ›¸æ¤œå‡º: {metrics['english']['detected']}ä»¶")
    print(f"   å¹³å‡ã‚¹ã‚³ã‚¢: {metrics['english']['avg_score']:.3f}")

    print(f"\n{'='*60}")
