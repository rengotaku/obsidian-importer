"""
Batch - ãƒãƒƒãƒå‡¦ç†

è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€æ‹¬å‡¦ç†ã¨ã‚µãƒãƒªãƒ¼è¡¨ç¤ºã‚’è¡Œã†ã€‚
"""
from __future__ import annotations

import json
import sys
import time
from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    pass

from normalizer.models import ProcessingResult
from normalizer.config import API_DELAY, VAULT_MAP, BASE_DIR
from normalizer.state.manager import (
    get_state,
    create_initial_state,
    update_state,
    save_state,
)
from normalizer.io.session import progress_bar, log_message
from normalizer.processing.single import process_single_file


# =============================================================================
# Batch Processing
# =============================================================================


def process_all_files(
    files: list[Path],
    preview: bool = False,
    quiet: bool = False,
    output_json: bool = False,
    state: dict | None = None
) -> dict:
    """è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†

    Args:
        files: å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
        preview: ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¢ãƒ¼ãƒ‰
        quiet: é€²æ—è¡¨ç¤ºæŠ‘åˆ¶
        output_json: JSONå‡ºåŠ›
        state: æ—¢å­˜ã®çŠ¶æ…‹ï¼ˆå†é–‹ç”¨ï¼‰

    Returns:
        å‡¦ç†çµæœã‚µãƒãƒªãƒ¼
    """
    state_mgr = get_state()

    # çŠ¶æ…‹åˆæœŸåŒ–
    if state is None:
        state = create_initial_state(files)
        save_state(state)

    # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–
    pending_names = set(state["pending"])
    files_to_process = [f for f in files if f.name in pending_names]

    # çµ±è¨ˆ
    stats = {
        "success": 0,
        "dust": 0,
        "error": 0
    }
    results: list[ProcessingResult] = []

    total = len(files_to_process)
    if not quiet and not output_json:
        log_message(f"\n{'='*60}")
        log_message(f"  å‡¦ç†é–‹å§‹: {total} ãƒ•ã‚¡ã‚¤ãƒ«")
        log_message(f"{'='*60}\n")

    for i, filepath in enumerate(files_to_process, 1):
        # é€²æ—è¡¨ç¤ºï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã®ã¿ï¼‰
        if not quiet and not output_json:
            sys.stdout.write(f"\r{progress_bar(i, total)} {filepath.name[:30]}")
            sys.stdout.flush()

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        result = process_single_file(
            filepath,
            preview=preview,
            quiet=True,
            output_json=False
        )
        results.append(result)

        # çµ±è¨ˆæ›´æ–°
        if result["success"]:
            if result["genre"] == "dust":
                stats["dust"] += 1
            else:
                stats["success"] += 1
        else:
            stats["error"] += 1

        # çŠ¶æ…‹æ›´æ–°
        state = update_state(state, result)
        save_state(state)

        # APIè² è·è»½æ¸›
        time.sleep(API_DELAY)

    # æ”¹è¡Œ
    if not quiet and not output_json:
        print()

    # å‡¦ç†å®Œäº†æ™‚ã‚‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚©ãƒ«ãƒ€ã¯ä¿æŒï¼ˆå±¥æ­´ãƒ»ãƒ­ã‚°å‚ç…§ç”¨ï¼‰
    # pending ãŒç©ºã§ã‚‚å‰Šé™¤ã—ãªã„

    # çµæœã‚µãƒãƒªãƒ¼
    summary = {
        "total": total,
        "stats": stats,
        "results": results
    }

    # JSONçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
    session_dir = state_mgr.session_dir
    if session_dir:
        result_file = session_dir / "results.json"
        result_file.write_text(
            json.dumps(summary, ensure_ascii=False, indent=2, default=str),
            encoding="utf-8"
        )

    # å‡ºåŠ›
    if output_json:
        print(json.dumps(summary, ensure_ascii=False, indent=2, default=str))
    elif not quiet:
        print_summary(stats, results, preview)

    return summary


# =============================================================================
# Summary Display
# =============================================================================


def print_summary(stats: dict, results: list[ProcessingResult], preview: bool = False) -> None:
    """å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    log_message(f"\n{'='*60}")
    log_message("  ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    log_message(f"{'='*60}")

    mode_label = "ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰" if preview else ""
    log_message(f"  âœ… æˆåŠŸ{mode_label}: {stats['success']} ãƒ•ã‚¡ã‚¤ãƒ«")
    log_message(f"  ğŸ—‘ï¸ Dust: {stats['dust']} ãƒ•ã‚¡ã‚¤ãƒ«")
    log_message(f"  âŒ ã‚¨ãƒ©ãƒ¼: {stats['error']} ãƒ•ã‚¡ã‚¤ãƒ«")

    # ç§»å‹•å…ˆVaultåˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
    vault_counts: dict[str, int] = {}
    for r in results:
        if r["success"] and r["genre"] and r["genre"] != "dust":
            genre = r["genre"]
            vault_counts[genre] = vault_counts.get(genre, 0) + 1
    if vault_counts:
        log_message(f"\nğŸ“‚ ç§»å‹•å…ˆVaultåˆ¥:")
        for genre, count in sorted(vault_counts.items(), key=lambda x: -x[1]):
            vault_path = VAULT_MAP.get(genre, BASE_DIR / "ãã®ä»–")
            log_message(f"    {genre}: {count} ãƒ•ã‚¡ã‚¤ãƒ« â†’ {vault_path.name}/")

    # æˆåŠŸã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°
    success_results = [r for r in results if r["success"] and r["genre"] != "dust"]
    if success_results:
        log_message(f"\nğŸ“ ç§»å‹•{'äºˆå®š' if preview else 'æ¸ˆã¿'}ãƒ•ã‚¡ã‚¤ãƒ«:")
        for r in success_results[:10]:
            log_message(f"  {Path(r['file']).name} â†’ {r['destination']}")
        if len(success_results) > 10:
            log_message(f"  ... ä»– {len(success_results) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")

    # dustãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°
    dust_results = [r for r in results if r["genre"] == "dust"]
    if dust_results:
        log_message(f"\nğŸ—‘ï¸ Duståˆ¤å®šãƒ•ã‚¡ã‚¤ãƒ«:")
        for r in dust_results[:5]:
            log_message(f"  {Path(r['file']).name}")
        if len(dust_results) > 5:
            log_message(f"  ... ä»– {len(dust_results) - 5} ãƒ•ã‚¡ã‚¤ãƒ«")

    # ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°
    error_results = [r for r in results if not r["success"] and r["error"]]
    if error_results:
        log_message(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿãƒ•ã‚¡ã‚¤ãƒ«:")
        for r in error_results:
            log_message(f"  {Path(r['file']).name}: {r['error']}")

    log_message(f"\n{'='*60}")
