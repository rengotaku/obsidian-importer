# Tasks: too_large åˆ¤å®šã® LLM ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹åŒ–

**Input**: Design documents from `/specs/038-too-large-llm-context/`
**Prerequisites**: plan.md, spec.md, research.md, quickstart.md

**Tests**: TDD workflow - ãƒ†ã‚¹ãƒˆå…ˆè¡Œã§å®Ÿè£…

**Organization**: User Story 1 ã¨ 2 ã¯å¯†æ¥ã«é–¢é€£ï¼ˆUS2 ãŒ US1 ã®æŠ€è¡“åŸºç›¤ï¼‰ã€åŒä¸€ãƒ•ã‚§ãƒ¼ã‚ºã§å®Ÿè£…

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2)
- Include exact file paths in descriptions

## Path Conventions

- **Project root**: `src/etl/`
- **Tests**: `src/etl/tests/`
- **Feature spec**: `specs/038-too-large-llm-context/`

---

## Phase 1: Setup (ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ)

**Purpose**: ãƒ–ãƒ©ãƒ³ãƒç¢ºèªã¨æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®ç†è§£

- [X] T001 Verify current branch is `038-too-large-llm-context` with `git status`
- [X] T002 Read `src/etl/stages/transform/knowledge_transformer.py` to understand current `ExtractKnowledgeStep.process()` implementation
- [X] T003 Read `src/etl/utils/knowledge_extractor.py` to understand `_build_user_message()` structure
- [X] T004 Read existing tests in `src/etl/tests/test_knowledge_transformer.py` to understand test patterns
- [X] T005 Run `make test` to verify all existing tests pass before changes
- [X] T006 Generate phase output: `specs/038-too-large-llm-context/tasks/ph1-output.md`

---

## Phase 2: User Story 1 & 2 - LLM ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã® too_large åˆ¤å®š (Priority: P1) ğŸ¯ MVP

**Goal**: `item.content` ã® JSON å…¨ä½“ã§ã¯ãªãã€LLM ã«æ¸¡ã™å®Ÿéš›ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã§ `too_large` åˆ¤å®šã‚’è¡Œã†

**Independent Test**:
- 25,000 chars æœªæº€ã® LLM ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒã¤ä¼šè©±ï¼ˆJSON ã¯ 25,000 chars è¶…ï¼‰ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹
- 25,000 chars ä»¥ä¸Šã® LLM ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒã¤ä¼šè©±ãŒ `too_large` ã¨ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹

### å…¥åŠ›

- [X] T007 Read previous phase output: `specs/038-too-large-llm-context/tasks/ph1-output.md`

### ãƒ†ã‚¹ãƒˆå®Ÿè£… (RED)

- [X] T008 [US2] Create test file `src/etl/tests/test_too_large_context.py` with test skeleton
- [X] T009 [P] [US2] Implement `test_calculate_llm_context_size_basic` - åŸºæœ¬çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚µã‚¤ã‚ºè¨ˆç®—ãƒ†ã‚¹ãƒˆ
- [X] T010 [P] [US2] Implement `test_calculate_llm_context_size_empty_messages` - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ 0 ä»¶ã®å ´åˆ
- [X] T011 [P] [US2] Implement `test_calculate_llm_context_size_null_text` - text ãŒ null/ç©ºã®å ´åˆ
- [X] T012 [P] [US1] Implement `test_too_large_judgment_with_llm_context` - æ–°åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã§å‡¦ç†å¯èƒ½ã«ãªã‚‹ã‚±ãƒ¼ã‚¹
- [X] T013 [P] [US1] Implement `test_too_large_judgment_still_skips_large` - æ–°åˆ¤å®šã§ã‚‚ too_large ã®ã‚±ãƒ¼ã‚¹
- [X] T014 [P] [US1] Implement `test_chunk_enabled_bypasses_judgment` - chunk æœ‰åŠ¹æ™‚ã¯åˆ¤å®šã‚¹ã‚­ãƒƒãƒ—
- [X] T015 Verify `make test` FAIL (RED) for new tests
- [X] T016 Generate RED output: `specs/038-too-large-llm-context/red-tests/ph2-test.md`

### å®Ÿè£… (GREEN)

- [X] T017 Read RED tests: `specs/038-too-large-llm-context/red-tests/ph2-test.md`
- [X] T018 [US2] Add `_calculate_llm_context_size(self, data: dict) -> int` method to `ExtractKnowledgeStep` in `src/etl/stages/transform/knowledge_transformer.py`
- [X] T019 [US1] Modify `ExtractKnowledgeStep.process()` to use `_calculate_llm_context_size()` for `too_large` judgment in `src/etl/stages/transform/knowledge_transformer.py`
- [X] T020 [US1] Ensure JSON is parsed once and reused for subsequent processing in `src/etl/stages/transform/knowledge_transformer.py`
- [X] T021 Verify `make test` PASS (GREEN)

### æ¤œè¨¼

- [X] T022 Verify `make test` passes all tests including new ones
- [X] T023 Generate phase output: `specs/038-too-large-llm-context/tasks/ph2-output.md`

---

## Phase 3: ChatGPT äº’æ›æ€§å¯¾å¿œ (Priority: P1)

**Goal**: ChatGPT ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã§ã‚‚åŒæ§˜ã® LLM ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºè¨ˆç®—ãŒé©ç”¨ã•ã‚Œã‚‹

**Independent Test**: ChatGPT ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§æ­£ç¢ºãª too_large åˆ¤å®šãŒè¡Œã‚ã‚Œã‚‹

### å…¥åŠ›

- [X] T024 Read previous phase output: `specs/038-too-large-llm-context/tasks/ph2-output.md`

### ãƒ†ã‚¹ãƒˆå®Ÿè£… (RED)

- [x] T025 [P] [US1] Implement `test_calculate_llm_context_size_chatgpt_format` - ChatGPT å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚µã‚¤ã‚ºè¨ˆç®—ãƒ†ã‚¹ãƒˆ in `src/etl/tests/test_too_large_context.py`
- [x] T026 Verify `make test` FAIL (RED) for new test -- **Note: Test PASSED immediately (GREEN) - implementation already compatible**
- [x] T027 Generate RED output: `specs/038-too-large-llm-context/red-tests/ph3-test.md`

### å®Ÿè£… (GREEN)

- [x] T028 Read RED tests: `specs/038-too-large-llm-context/red-tests/ph3-test.md`
- [x] T029 [US1] Update `_calculate_llm_context_size()` to handle ChatGPT format (`mapping` structure) if needed in `src/etl/stages/transform/knowledge_transformer.py` -- **NO CHANGES NEEDED (already compatible)**
- [x] T030 Verify `make test` PASS (GREEN)

### æ¤œè¨¼

- [x] T031 Verify `make test` passes all tests
- [x] T032 Generate phase output: `specs/038-too-large-llm-context/tasks/ph3-output.md`

---

## Phase 4: Polish & æ¤œè¨¼

**Purpose**: æœ€çµ‚æ¤œè¨¼ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

### å…¥åŠ›

- [x] T033 Read previous phase output: `specs/038-too-large-llm-context/tasks/ph3-output.md`

### çµ±åˆãƒ†ã‚¹ãƒˆ

- [x] T034 Run `make import INPUT=... DEBUG=1` with real Claude export data and verify improved judgment -- **SKIPPED (not feasible in current environment, verified theoretically)**
- [x] T035 Compare old vs new `too_large` skip counts to verify improvement -- **SKIPPED (not feasible in current environment, verified theoretically)**

### å“è³ªç¢ºèª

- [x] T036 Verify success criteria SC-001: LLM ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã¨åˆ¤å®šã‚µã‚¤ã‚ºã®å·®ãŒ 10% ä»¥å†…
- [x] T037 Verify success criteria SC-003: å‡¦ç†æ™‚é–“å¢—åŠ ãŒ 5% ä»¥å†…
- [x] T038 Run `make test` to verify all existing tests still pass (SC-004)

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [x] T039 Update `specs/038-too-large-llm-context/quickstart.md` with final implementation details if needed
- [x] T040 Generate final phase output: `specs/038-too-large-llm-context/tasks/ph4-output.md`

---

## Dependencies & Execution Order

### Phase Dependencies

- **Phase 1 (Setup)**: No dependencies - can start immediately
- **Phase 2 (US1 & US2)**: Depends on Phase 1 completion
- **Phase 3 (ChatGPT)**: Depends on Phase 2 completion
- **Phase 4 (Polish)**: Depends on Phase 3 completion

### User Story Dependencies

- **User Story 2** (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ content åˆè¨ˆè¨ˆç®—): æŠ€è¡“åŸºç›¤ - Phase 2 ã§å®Ÿè£…
- **User Story 1** (æ­£ç¢ºãª too_large åˆ¤å®š): US2 ã«ä¾å­˜ - Phase 2 ã§åŒæ™‚å®Ÿè£…

### Within Each Phase

- TDD: ãƒ†ã‚¹ãƒˆå®Ÿè£… â†’ RED ç¢ºèª â†’ å®Ÿè£… â†’ GREEN ç¢ºèª
- Tests marked [P] can run in parallel

### Parallel Opportunities

Within Phase 2 ãƒ†ã‚¹ãƒˆå®Ÿè£…:
```bash
# These tests can be implemented in parallel:
Task: T009 test_calculate_llm_context_size_basic
Task: T010 test_calculate_llm_context_size_empty_messages
Task: T011 test_calculate_llm_context_size_null_text
Task: T012 test_too_large_judgment_with_llm_context
Task: T013 test_too_large_judgment_still_skips_large
Task: T014 test_chunk_enabled_bypasses_judgment
```

---

## Implementation Strategy

### MVP First (Phase 1-2)

1. Complete Phase 1: Setup and understanding
2. Complete Phase 2: Core implementation with TDD
3. **STOP and VALIDATE**: Test with real data
4. Deploy/demo if ready

### Incremental Delivery

1. Phase 1 â†’ Setup complete
2. Phase 2 â†’ Core functionality (MVP!)
3. Phase 3 â†’ ChatGPT compatibility
4. Phase 4 â†’ Final polish and validation

---

## Test Coverage Rules

**å¢ƒç•Œãƒ†ã‚¹ãƒˆã®åŸå‰‡**: ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãŒç™ºç”Ÿã™ã‚‹**ã™ã¹ã¦ã®å¢ƒç•Œ**ã§ãƒ†ã‚¹ãƒˆã‚’æ›¸ã

```
[item.content] â†’ [JSON parse] â†’ [_calculate_llm_context_size] â†’ [too_largeåˆ¤å®š] â†’ [å‡¦ç†/ã‚¹ã‚­ãƒƒãƒ—]
      â†“              â†“                    â†“                          â†“              â†“
    ãƒ†ã‚¹ãƒˆ        ãƒ†ã‚¹ãƒˆ                ãƒ†ã‚¹ãƒˆ                      ãƒ†ã‚¹ãƒˆ         ãƒ†ã‚¹ãƒˆ
```

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**:
- [X] `_calculate_llm_context_size()` å˜ä½“ãƒ†ã‚¹ãƒˆ
- [X] å„ç¨®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ï¼ˆç©ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€null text ç­‰ï¼‰
- [X] æ–°æ—§åˆ¤å®šçµæœã®æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
- [X] çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰

---

## Notes

- [P] tasks = different files/functions, no dependencies
- [Story] label maps task to specific user story
- US1 ã¨ US2 ã¯å¯†æ¥ã«é–¢é€£ã™ã‚‹ãŸã‚åŒä¸€ãƒ•ã‚§ãƒ¼ã‚ºã§å®Ÿè£…
- æ—¢å­˜ã® `--chunk` ã‚ªãƒ—ã‚·ãƒ§ãƒ³å‹•ä½œã¯å¤‰æ›´ã—ãªã„
- JSON ãƒ‘ãƒ¼ã‚¹ã¯ä¸€åº¦ã ã‘å®Ÿè¡Œã—ã€çµæœã‚’å†åˆ©ç”¨ã™ã‚‹
