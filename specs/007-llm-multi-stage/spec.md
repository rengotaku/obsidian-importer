# Feature Specification: LLM Multi-Stage Processing

**Feature Branch**: `007-llm-multi-stage`
**Created**: 2026-01-13
**Status**: Draft
**Input**: User description: "LLMの処理を分ける。また順番も検討する。時間は掛かっても良い。精度を重視"

## Background

### Current Problem

現在の `ollama_normalizer.py` は1回のLLM呼び出しで以下の全てを同時に処理している：
- ジャンル分類（genre）
- 信頼度算出（confidence）
- dust判定（is_dust）
- タイトル生成（frontmatter.title）
- タグ付け（frontmatter.tags）
- 本文正規化（normalized_content）
- 改善リスト（improvements_made）

この「全部入り」アプローチにより、`@plan/20260112_174824` では91ファイル中35件（38%）でエラーが発生した。

**エラーパターン分析:**

| エラー種別 | 件数 | 原因 |
|-----------|------|------|
| JSON形式の応答がありません | 29件 | LLMがJSON以外の形式で応答 |
| JSONパースエラー | 6件 | 不正なJSON構造 |

### Proposed Solution

LLM処理を複数段階に分割し、各段階で特化した処理を行う。時間がかかっても精度を重視する。

## User Scenarios & Testing *(mandatory)*

### User Story 1 - 段階的処理によるエラー削減 (Priority: P1)

ユーザーが `@index/` フォルダ内のMarkdownファイルを処理する際、LLM処理が複数段階に分かれて実行され、各段階の出力が検証される。これにより、1つの段階で失敗しても他の段階の結果は保持され、全体のエラー率が大幅に低下する。

**Why this priority**: 現在の38%エラー率を大幅に削減することが最優先。エラーが減れば手動介入が減り、ユーザーの作業効率が向上する。

**Independent Test**: 既知のエラーを起こしたファイル群に対して処理を実行し、エラー率が10%以下に低下することを確認できる。

**Acceptance Scenarios**:

1. **Given** 以前エラーとなった35件のファイル, **When** 新しい段階的処理を実行, **Then** エラー率が10%以下に低下する
2. **Given** 1つの段階でJSON解析が失敗, **When** 次の段階に進む, **Then** 前段階の有効な結果は保持され、失敗した段階のみリトライされる
3. **Given** 全段階が成功, **When** 最終結果を確認, **Then** 現行と同等以上の品質の分類・正規化結果が得られる

---

### User Story 2 - 処理順序の最適化 (Priority: P2)

処理順序が「簡単な判定から難しい判定へ」「依存関係を考慮した順序」で実行され、効率的かつ精度の高い結果が得られる。

**Why this priority**: 処理順序の最適化により、早期にdust判定できればその後の処理をスキップでき、無駄なLLM呼び出しを削減できる。

**Independent Test**: dustファイルに対して処理を実行し、dust判定後に後続の処理がスキップされることを確認できる。

**Acceptance Scenarios**:

1. **Given** 明らかなdustファイル（空、意味不明）, **When** 処理を実行, **Then** 最初のdust判定で終了し、タイトル生成・正規化はスキップされる
2. **Given** 英語文書, **When** 処理を実行, **Then** 英語判定に基づいて翻訳処理がスキップされる
3. **Given** 長文技術ドキュメント, **When** 処理を実行, **Then** 各段階で適切なコンテキスト量が使用される

---

### User Story 3 - 段階別リトライ機構 (Priority: P3)

特定の段階でLLM応答が不正な場合、その段階のみをリトライでき、最終的に有効な結果を得られる確率が向上する。

**Why this priority**: リトライにより一時的なLLM不安定性を吸収できるが、根本的なエラー削減はP1の段階分割で実現されるため優先度は下がる。

**Independent Test**: 意図的に不正な応答を返すモック環境で、リトライ後に正常な結果が得られることを確認できる。

**Acceptance Scenarios**:

1. **Given** 段階Aで不正なJSON応答, **When** リトライを実行, **Then** 最大3回までリトライされ、成功すれば次段階に進む
2. **Given** 3回リトライしても失敗, **When** 処理を継続, **Then** その段階はデフォルト値で補完され、次段階に進む
3. **Given** リトライが発生, **When** ログを確認, **Then** リトライ回数と理由が記録されている

---

### Edge Cases

- **超長文ファイル**: コンテンツが極端に長い場合、各段階で適切にトランケーションされる
- **マルチバイト文字を含むコード**: コード内のエスケープシーケンスがJSON応答に混入しない
- **既存frontmatterあり**: 既存のメタデータを適切に処理し、重複しない
- **ネットワークエラー**: API呼び出し失敗時は適切にエラーハンドリングされる

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: システムはLLM処理を複数の独立した段階に分割して実行できなければならない
- **FR-002**: 各段階の出力は個別に検証され、不正な場合はその段階のみリトライされなければならない
- **FR-003**: dust判定が確定した場合、後続の正規化処理はスキップされなければならない
- **FR-004**: 各段階の処理結果はログに記録されなければならない
- **FR-005**: 全段階が完了した場合、現行と同じ形式の最終結果が出力されなければならない
- **FR-006**: 段階間のデータ受け渡しは明示的に定義されなければならない
- **FR-007**: リトライ回数は設定可能で、デフォルトは3回とする

### Key Entities

- **Stage（処理段階）**: 各LLM処理の単位。入力、出力形式、検証ロジックを持つ
- **StageResult（段階結果）**: 各段階の処理結果。成功/失敗、出力データ、エラー情報を含む
- **ProcessingPipeline（処理パイプライン）**: 複数の段階を順序付けて実行する制御フロー
- **FileContext（ファイルコンテキスト）**: 処理対象ファイルの情報と各段階の累積結果

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: 以前エラーとなった35件のファイルに対するエラー率が10%以下に低下する
- **SC-002**: 全ファイル処理において、最終的なジャンル分類精度が95%以上を維持する
- **SC-003**: dust判定ファイルに対する処理時間が現行比50%以下となる（後続処理スキップにより）
- **SC-004**: 処理ログから各段階の成功/失敗状況が明確に把握できる
- **SC-005**: リトライにより救済されたファイル数が記録され、10%以上のエラー削減に貢献する

## Assumptions

- Ollama APIは基本的に安定しており、リトライで解決できる一時的なエラーが大半である
- 処理時間の増加（段階分割による複数API呼び出し）はユーザーにとって許容可能である
- 各段階のプロンプトはシンプルになることでLLMの応答精度が向上する
- ローカルLLMの特性として、複雑な指示より単純な指示の方が遵守されやすい

## Processing Pipeline Design

処理は「ルールベース前処理 → LLM段階処理 → ルールベース後処理」の3層構造で実行する。

### 処理フロー概要

```
Pre-processing（ルールベース）
    ↓
Stage 1: Dust判定（LLM）
    ↓ dustなら終了
Stage 2: ジャンル分類（LLM）
    ↓
Stage 3: コンテンツ正規化（LLM）  ← 正規化を先に実施
    ↓
Stage 4: タイトル・タグ生成（LLM）  ← 正規化後のコンテンツから生成
    ↓
Post-processing（ルールベース）
```

### 順序設計の根拠

1. **英語判定は正規化の前**: 正規化で翻訳されると英語判定ができなくなるため、Pre-processingで実施
2. **正規化はタイトル/タグ生成の前**: 整理されたコンテンツからより適切なタイトル・タグを生成できる
3. **ジャンル情報は正規化に活用**: ジャンルに応じた適切な整形が可能

---

### Pre-processing（ルールベース）

LLM呼び出し前に実行する事前処理。

| 処理 | 手法 | 説明 |
|------|------|------|
| 空ファイル判定 | ルールベース | `len(content.strip()) == 0` で即dust確定 |
| 極短文判定 | ルールベース | 閾値（50文字未満）で即dust確定 |
| 英語文書判定 | ルールベース | `is_complete_english_document()` を流用 |
| 日付抽出 | ルールベース | `extract_date_from_filename()` を流用 |
| テンプレート残骸検出 | ルールベース | `[TODO]`, `Lorem ipsum` 等のパターン検出 |

**出力**: `PreProcessingResult`
- `is_empty`: bool
- `is_too_short`: bool
- `is_english_doc`: bool
- `english_score`: float
- `extracted_date`: string
- `has_template_markers`: bool

---

### Stage 1: Dust判定（LLM）

Pre-processingで除外されなかったファイルに対し、コンテンツの価値を判定。

| 判定項目 | 手法 | 説明 |
|---------|------|------|
| 意味のないコンテンツ | **LLM** | 「テスト」「あああ」等の判定 |
| 断片的すぎるメモ | **LLM** | 文脈なしで価値判断できないもの |

- **入力**: ファイル内容（先頭2000文字）
- **出力**: `{is_dust: bool, dust_reason: string | null, confidence: float}`
- **目的**: 価値のないファイルを早期に除外し、後続処理をスキップ
- **終了条件**: `is_dust == true` の場合、Stage 2以降をスキップ

---

### Stage 2: ジャンル分類（LLM）

6ジャンルへの分類と関連キーワード抽出。

| 判定項目 | 手法 | 説明 |
|---------|------|------|
| 6ジャンル分類 | **LLM** | エンジニア/ビジネス/経済/日常/その他/dust |
| 信頼度算出 | **LLM** | 0.0-1.0の確信度 |
| 関連キーワード | **LLM** | 検索用キーワード3-5個 |

- **入力**: ファイル内容 + 英語フラグ（Pre-processingから）
- **出力**: `{genre: string, confidence: float, related_keywords: string[]}`
- **目的**: 適切なVaultへの振り分けと検索性向上

---

### Stage 3: コンテンツ正規化（LLM）

本文の整形と改善。タイトル/タグ生成の前に実施することで、より良い結果を得る。

| 判定項目 | 手法 | 説明 |
|---------|------|------|
| 翻訳要否 | **ルールベース** | Pre-processingの英語フラグで判定 |
| 冗長表現の簡潔化 | **LLM** | 「〜ということなのですが」→「〜である」 |
| 不完全な文の補完 | **LLM** | 文脈から適切に補完 |
| 断片的英語メモの整理 | **LLM** | 自然な日本語に変換（英語文書以外） |
| コードブロック保持 | **ルールベース** | 正規表現で検出・保護 |

- **入力**: ファイル内容 + ジャンル + 英語フラグ
- **出力**: `{normalized_content: string, improvements_made: string[]}`
- **目的**: 読みやすく整理されたコンテンツの生成
- **注意**: 英語文書の場合は翻訳せず、構造のみ整理

---

### Stage 4: タイトル・タグ生成（LLM）

正規化後のコンテンツから適切なタイトルとタグを生成。

| 判定項目 | 手法 | 説明 |
|---------|------|------|
| タイトル生成 | **LLM** | ファイル名に適した自然なタイトル |
| タグ生成 | **LLM** | 3-5個の適切なタグ |
| 日付決定 | **ルールベース** | Pre-processingで抽出済み、なければ空 |

- **入力**: 正規化後コンテンツ + ジャンル + 抽出済み日付
- **出力**: `{title: string, tags: string[], created: string}`
- **目的**: 正規化されたきれいなコンテンツから適切なメタデータを生成

---

### Post-processing（ルールベース）

LLM出力の検証と修正。

| 処理 | 手法 | 説明 |
|------|------|------|
| タイトル検証 | ルールベース | `validate_title()` - 禁止文字、長さチェック |
| タイトル修正 | ルールベース | `normalize_filename()` - 問題があれば自動修正 |
| タグ検証 | ルールベース | `validate_tags()` - 個数、形式チェック |
| タグ正規化 | ルールベース | `normalize_tags()` - 重複除去、正規化 |
| Markdown形式検証 | ルールベース | `validate_markdown_format()` - 見出し、空行チェック |

**出力**: 最終的な `NormalizationResult`（現行と同じ形式）

---

### LLM呼び出し回数まとめ

| ケース | LLM呼び出し回数 | 備考 |
|--------|----------------|------|
| 空/極短ファイル | 0回 | Pre-processingで終了 |
| dustファイル | 1回 | Stage 1で終了 |
| 通常ファイル | 4回 | 全Stage実行 |
| リトライ発生時 | +1〜3回/段階 | 失敗した段階のみ |

各段階は独立したプロンプトを持ち、出力形式がシンプルなためJSON解析エラーが減少する。
