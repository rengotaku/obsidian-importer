# Feature Specification: チャンク処理の共通化

**Feature Branch**: `035-chunking-mixin`
**Created**: 2026-01-26
**Status**: Draft
**Input**: User description: "チャンク処理の共通化"

## 背景と課題

現在、ETLパイプラインにおけるチャンク分割処理（大きな会話を複数の小さな単位に分割する機能）は、ClaudeExtractorにのみ実装されている。ChatGPTExtractor、GitHubExtractorなど他のプロバイダーでは未実装のため、大きなファイル（25,000文字超）の処理時にタイムアウトや失敗が発生している。

**現状の問題点**:
- チャンク分割ロジックがClaudeExtractor内に埋め込まれている
- 新規プロバイダー追加時に毎回チャンク処理を実装する必要がある
- ChatGPTインポートで298KB（約30万文字）の会話が失敗している

**ビジネス価値**:
- 全プロバイダーで大きなファイルを確実に処理できるようになる
- 新規プロバイダー追加時の実装コストが削減される
- インポート成功率が向上し、ユーザー体験が改善される

## User Scenarios & Testing

### User Story 1 - ChatGPTからの大規模会話インポート (Priority: P1)

ユーザーとして、ChatGPTからエクスポートした大規模な会話（30万文字を超えるものを含む）を、失敗なくObsidianにインポートしたい。これにより、長期間のプロジェクト相談や技術的な議論の履歴を完全に保存できる。

**Why this priority**: ChatGPTインポートは現在27件が失敗しており、最も影響を受けているユーザーシナリオ。大規模会話の保存は知識管理の核心機能である。

**Independent Test**: ChatGPTエクスポートZIPファイル（大きな会話を含む）をインポートし、全件が正常に処理されることを確認できる。

**Acceptance Scenarios**:

1. **Given** 298,622文字の会話を含むChatGPTエクスポートがある, **When** `make import PROVIDER=openai CHUNK=1`を実行する, **Then** 会話が複数のチャンクに分割され、すべてのチャンクが正常に処理される
2. **Given** 25,000文字未満の会話がある, **When** インポートを実行する, **Then** チャンク分割されずにそのまま処理される
3. **Given** チャンク分割された会話がある, **When** 処理完了後にファイルを確認する, **Then** 各チャンクが個別のMarkdownファイルとして保存され、元の会話との関連が明確である
4. **Given** 大規模会話を分割して処理したい, **When** `--chunk`オプションを指定してインポートを実行する, **Then** チャンク分割が有効化され、閾値超過の会話が複数のチャンクに分割される

---

### User Story 2 - 新規プロバイダーでの自動チャンク対応 (Priority: P2)

開発者として、新しいプロバイダー（例：GitHubブログ）を追加する際に、最小限のコードでチャンク分割機能を利用したい。これにより、開発工数を削減し、一貫した動作を保証できる。

**Why this priority**: プロバイダー拡張性はETLパイプラインの長期的な保守性に直結する。ただし、既存の失敗解消（P1）が優先。

**Independent Test**: 新規プロバイダーを追加し、共通チャンク機能を呼び出すだけで大きなファイルが正しく分割されることを確認できる。

**Acceptance Scenarios**:

1. **Given** 新規プロバイダーを実装している, **When** 基底クラスを継承する, **Then** 抽象メソッド（`_discover_raw_items`、`_build_conversation_for_chunking`）の実装が強制され、チャンク分割が自動適用される
2. **Given** 共通チャンク機能を利用するプロバイダーがある, **When** チャンクサイズ閾値を変更する, **Then** 全プロバイダーで一貫してその閾値が適用される
3. **Given** 新規プロバイダーで抽象メソッドを実装していない, **When** プロバイダーをインスタンス化する, **Then** エラーが発生し、実装漏れが検出される

---

### User Story 3 - ClaudeExtractorのリファクタリング (Priority: P3)

開発者として、既存のClaudeExtractorを共通チャンク機能を使用するようにリファクタリングしたい。これにより、コードの重複を排除し、保守性を向上させる。

**Why this priority**: 機能的には既に動作しているため、新機能追加より優先度は低い。ただし、長期的な保守性のために必要。

**Independent Test**: リファクタリング後もClaudeインポートが既存と同じ結果を返すことをテストで確認できる。

**Acceptance Scenarios**:

1. **Given** 既存のClaudeExtractor実装がある, **When** 共通チャンク機能を使用するようにリファクタリングする, **Then** 既存のテストがすべてパスし、動作に変更がない
2. **Given** リファクタリング後のClaudeExtractorがある, **When** 大きな会話をインポートする, **Then** 以前と同じチャンク分割結果が得られる

---

### Edge Cases

- チャンクサイズ閾値（25,000文字）ちょうどの会話は分割されない（閾値超過時のみ分割）
- メッセージが1つしかない超大規模会話は、メッセージ内部では分割せず警告を出力する
- 空の会話（メッセージ数0）はチャンク分割せずスキップする
- チャンク分割時にオーバーラップメッセージ（文脈維持用）が正しく含まれる
- デフォルト（チャンク無効）時、閾値（25,000文字）を超えるファイルは LLM 処理をスキップし、frontmatter に `too_large: true` を追記して `status=SKIPPED` として記録する
- `--chunk`オプション指定時、閾値超過ファイルは分割されて全チャンクが LLM 処理される

## Requirements

### Functional Requirements

- **FR-001**: システムは、全プロバイダー（Claude、ChatGPT、GitHub等）で共通して使用できるチャンク分割機能を提供しなければならない
- **FR-002**: チャンク分割機能は、会話の総文字数が閾値（デフォルト25,000文字）を超えた場合にのみ分割を実行しなければならない
- **FR-003**: チャンク分割時、文脈維持のためにオーバーラップメッセージ（デフォルト2件）を含めなければならない
- **FR-004**: 各プロバイダーは、基底クラスの抽象メソッドとしてプロバイダー固有の変換関数を実装しなければならない（実装漏れ時はエラーとなる）
- **FR-005**: チャンク分割されたアイテムは、親アイテムとの関連を示すメタデータ（parent_item_id、chunk_index、total_chunks）を持たなければならない
- **FR-006**: 既存のChunkerクラス（src/etl/utils/chunker.py）を再利用し、新たなチャンク分割ロジックの重複を避けなければならない
- **FR-007**: チャンク分割機能はデフォルトで無効であり、`--chunk`オプションを指定した場合のみ有効化される。無効時、閾値を超えるファイルは LLM 処理をスキップし、frontmatter に `too_large: true` を追記しなければならない
- **FR-008**: チャンク分割処理は基底クラス（BaseStage）に組み込み、新規プロバイダー実装時に機能漏れが発生しない設計としなければならない

### Key Entities

- **BaseStage（拡張）**: 全Extractorの基底クラス。チャンク分割機能を組み込み、Template Methodパターンで自動適用する。`discover_items()`が内部で`_discover_raw_items()`を呼び出し、結果に対してチャンク処理を自動適用する。
- **_discover_raw_items（抽象メソッド）**: 各プロバイダーが実装必須。生データの取得のみを担当し、チャンク処理を意識しない。
- **_build_conversation_for_chunking（抽象メソッド）**: 各プロバイダーが実装必須。プロバイダー固有の会話形式をConversationProtocolに変換する。
- **ProcessingItem**: チャンク分割後のアイテム。metadata内にis_chunked、parent_item_id、chunk_index、total_chunksを含む。
- **ConversationProtocol**: 各プロバイダーの会話形式を抽象化するインターフェース。チャンク分割判定に必要な情報（messages、total_chars）を提供する。

## Success Criteria

### Measurable Outcomes

- **SC-001**: ChatGPTインポートで以前失敗していた27件の大規模会話が、すべて正常に処理される
- **SC-002**: 298,622文字の会話が12個以下のチャンクに分割され（25,000文字/チャンク基準）、各チャンクが個別に処理される
- **SC-003**: 新規プロバイダー追加時のチャンク機能実装に必要なコード行数が、50行以下（変換関数のみ）である
- **SC-004**: ClaudeExtractorリファクタリング後、既存の全テストが変更なしでパスする
- **SC-005**: 全プロバイダーでインポート成功率が99%以上を達成する（チャンク分割対象ファイルを含む）
- **SC-006**: 新規プロバイダーで抽象メソッドを実装しない場合、インスタンス化時にTypeErrorが発生する（機能漏れ防止）

## 前提条件

- 既存のChunkerクラス（src/etl/utils/chunker.py）はプロバイダー非依存のProtocol-based設計であり、再利用可能
- チャンクサイズ閾値（25,000文字）とオーバーラップメッセージ数（2件）は現行のClaudeExtractor設定を踏襲
- T034設計方針（"Chunking at discover_items level"）を維持し、Extract Stageでチャンク分割を実行

## 設計方針

### Template Methodパターンの採用

機能漏れ防止のため、Mixinパターンではなく**Template Methodパターン**を採用する。

**Mixinの問題点**:
- 継承の追加を忘れる可能性がある
- 初期化メソッドの呼び出しを忘れる可能性がある
- チャンク処理の呼び出しを忘れる可能性がある

**Template Methodの利点**:
- 基底クラスが処理フローを制御し、チャンク処理を自動適用
- 抽象メソッドにより実装漏れをコンパイル時に検出
- 新規プロバイダー開発者はチャンク処理を意識する必要がない

**処理フロー**:
```
discover_items() [BaseStage - 自動]
    ↓
_discover_raw_items() [各プロバイダー - 実装必須]
    ↓
_chunk_if_needed() [BaseStage - 自動]
    ↓
_build_conversation_for_chunking() [各プロバイダー - 実装必須]
```
