# 検証結果: プロンプト改善の効果測定

**実施日**: 2026-02-15
**モデル**: gpt-oss:20b
**設定**: temperature=0.2, num_predict=16384, timeout=300

## サンプル

| ID | ファイル | カテゴリ | 元サイズ | file_id |
|----|---------|---------|---------|---------|
| S1 | キッザニアの仕事体験とキッゾ給料システム.md | 短い会話 | 501 chars | 389c1d35f44f |
| S2 | SREとDevOps おすすめ書籍まとめ.md | 中程度 | 1,867 chars | edb42c441a83 |
| S3 | 千葉のSwitch2販売実績.md | 表形式含む | 4,994 chars | 8b8869107b00 |
| S4 | JavaScript 3D デッサン人形作成.md | コード含む | 2,793 chars | 1b1679e5dd57 |
| S5 | OpenMediaVault (chunk1/5) | **チャンク分割** | 82,515 chars | 69eaf2784b59_chunk1 |

## プロンプトバリエーション

### V1: 現行プロンプト

`src/obsidian_etl/utils/prompts/knowledge_extraction.txt` をそのまま使用

### V2: 定性的指示追加

```text
## 分析・考察の記述

会話に分析や考察が含まれる場合:
- **理由・背景**: 「なぜそうなるか」を必ず説明
- **パターン・傾向**: データから読み取れる傾向を明記
- **推奨・アドバイス**: 結論だけでなく根拠も記述

## 表形式データの保持

元の会話に表形式データがある場合:
- **必ず Markdown 表形式で保持**
- 数値・日付は省略せず記載
- 表の前に簡潔な説明を追加
```

## 結果

### 初回実行結果

| Sample | カテゴリ | 元サイズ | V1 出力 | V1 圧縮率 | V2 出力 | V2 圧縮率 | 改善幅 |
|--------|---------|---------|---------|----------|---------|----------|--------|
| S1 | 短い | 501 | 781 | 155.9% | 897 | 179.0% | +23.1% |
| S2 | 中 | 1,867 | 1,224 | 65.6% | 1,412 | 75.6% | +10.0% |
| S3 | 表形式 | 4,994 | 353 | **7.1%** | 1,207 | **24.2%** | **+17.1%** |

### 詳細出力（再実行結果含む）

| Sample | カテゴリ | 元サイズ | V1 出力 | V1 圧縮率 | V2 出力 | V2 圧縮率 |
|--------|---------|---------|---------|----------|---------|----------|
| S1 | 短い | 501 | 630 | 125.7% | 747 | 149.1% |
| S2 | 中 | 1,867 | 1,167 | 62.5% | 1,483 | 79.4% |
| S3 | 表形式 | 4,994 | 491 | 9.8% | 758 | 15.2% |
| S4 | コード | 2,793 | 2,099 | 75.2% | 5,678 | 203.3% |
| S5 | **チャンク** | **82,515** | **0** | **0.0%** ❌ | **2,492** | **3.0%** ❌ |

**注**: LLM出力は毎回変動する。S3はV1でも9.8%、V2で15.2%と、初回より低い結果も出た。

### ⚠️ S5（チャンク分割）の重大な問題

82,515 chars の大量入力で LLM が破綻:
- **V1: 0 chars** - 完全に空出力
- **V2: 2,492 chars (3.0%)** - 出力はあるが、**内容が元の会話と無関係**（SSH の説明が出力された）

**原因の推測**:
- コンテキストウィンドウの限界を超えている
- チャンク分割戦略の見直しが必要

### 出力ファイル

```
specs/052-improve-summary-quality/verification-outputs/
├── S1-389c1d35f44f/
│   ├── metadata.md
│   ├── original.md
│   ├── v1-output.md
│   └── v2-output.md
├── S2-edb42c441a83/
│   └── ...
├── S3-8b8869107b00/
│   └── ...
├── S4-1b1679e5dd57/        # コード含む
│   └── ...
└── S5-69eaf2784b59_chunk1/ # チャンク分割（問題あり）
    └── ...
```

## 分析

### S1（短い会話）

- 両バージョンとも元サイズを超える出力（100%超）
- 短い会話は圧縮ではなく拡張される傾向
- **結論**: 短い会話は問題なし

### S2（中程度）

- V1: 66% → V2: 76%（+10%改善）
- 既にしきい値（20%）を大幅に超えている
- **結論**: 改善効果あり、問題なし

### S3（表形式含む・問題ケース）

- **V1: 7.1%** - しきい値 20% を大幅に下回る（現状の問題）
- **V2: 24.2%** - しきい値 20% をクリア
- 改善幅 +17.1% は全サンプル中最大
- **結論**: 定性的指示で問題解決

### S4（コード含む）

- V1: 75.2% - しきい値を大幅に超える ✅
- V2: 203.3% - コードを含めて拡張
- **結論**: コード含む会話は問題なし

### S5（チャンク分割・重大問題）

- **V1: 0.0%** - 完全に空出力 ❌
- **V2: 3.0%** - 出力あるが内容が元の会話と無関係 ❌
- 元サイズ 82,515 chars はモデルの処理限界を超えている
- **結論**: チャンク分割戦略の見直しが必要（別 Issue として対応）

## V3: 簡潔さ重視プロンプト

V2 の水増し傾向（特に S4: 203%）を抑制するため、以下を調整:
- コードは 10 行以内のみ含める
- 長いコードは概要のみ
- 情報量の目安を削除

| Sample | V3 出力 | V3 圧縮率 |
|--------|---------|----------|
| S1 | 546 | 109.0% |
| S2 | 955 | 51.2% |
| S3 | 300-1248 | 6-25% ⚠️ 不安定 |
| S4 | 2,157 | 77.2% |

**課題**: S3（表形式）の出力が不安定

## V4: マーカーアプローチ

コードをマーカー（`**code-1**`）に置換して LLM に渡し、後で復元する方式。

| Sample | 結果 | 備考 |
|--------|------|------|
| S1 | OK | マーカーなし |
| S2 | OK | コード 1 個保持 |
| S3 | REVIEW | マーカー全欠落 |
| S4 | OK | コード 3 個保持 |

**課題**: 表マーカーは LLM に無視されやすい

## V5: 表を後から追加する方式（採用）

**アプローチ**:
1. **コード**: マーカー化 → LLM → 復元（フォールバック付き）
2. **表**: 抽出して LLM に渡さない → 後から見出し付きで追加

**前処理**:
- コードブロック → `**code-N**` マーカーに置換
- 表 → 抽出して保持（同じカラム名は最新のみ）
- 表の直前の見出し（## ...）も一緒に保持

**後処理**:
- コードマーカー → 元のコードに復元
- コードマーカー全欠落 → REVIEW 行き
- 表 → `## データ` セクションとして末尾に追加

### V5 最終検証結果

| Sample | 元 | 出力 | 圧縮率 | Code | Table | 状態 |
|--------|-----|------|--------|------|-------|------|
| S1 | 501 | 536 | 107.0% | 0 | 0 | ✅ OK |
| S2 | 1,867 | 1,170 | 62.7% | 1 | 0 | ✅ OK |
| S3 | 4,994 | 1,015 | 20.3% | 1 | 1 | 🔍 REVIEW |
| S4 | 2,793 | 2,315 | 82.9% | 3 | 0 | ✅ OK |

**S3 出力構造**:
```
[LLM生成の要約]
- 販売パターン分析
- 今週末の見込み
- 推奨行動

---

## データ
### ヨドバシカメラ千葉店 Switch2販売実績【修正版】
[元の表データ]
```

## 結論

### 推奨アプローチ

**V5（表を後から追加する方式）を採用**

理由:
1. 表形式データが確実に保持される
2. コードマーカーは安定して動作
3. LLM は要約に集中でき、出力品質が向上
4. 偽コード（Twitter データ等）は REVIEW で人間確認

### 実装方針

1. **前処理モジュール**: `marker_preprocessor.py`
   - `preprocess()`: コードマーカー化 + 表抽出
   - `postprocess()`: マーカー復元 + 表追加

2. **プロンプト**: V3 ベース + コードマーカー指示

3. **REVIEW 判定**:
   - コードマーカー全欠落 → REVIEW 行き
   - 表は常に追加（REVIEW 対象外）

### 実装ファイル

```
specs/052-improve-summary-quality/
├── v3-prompt.txt              # V3 プロンプト
├── marker_preprocessor.py     # 前処理・後処理モジュール
├── run_v5_final.py            # V5 検証スクリプト
└── verification-outputs/
    ├── S1-*/v5-output.md
    ├── S2-*/v5-output.md
    ├── S3-*/v5-output.md
    └── S4-*/v5-output.md
```

### ⚠️ 追加発見: チャンク分割の問題

**S5（82,515 chars）の検証で判明した問題**:
- 現在のチャンク分割（25,000 chars）後もサイズが大きすぎる
- LLM が処理できず、空出力または無関係な内容を出力
- **対応**: 別 Issue として対応が必要（このスコープ外）

### 次のステップ

1. ✅ spec.md を更新（実装方針を反映）
2. ✅ tasks.md を更新
3. ✅ V5 方式の検証完了
4. ⏳ V5 方式を本実装に統合
5. 🆕 チャンク分割問題は別 Issue で対応
